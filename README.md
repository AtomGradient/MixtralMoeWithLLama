# MixtralMoeWithLLama

A local llama.cpp tool for runing Mixtral 8X7B Instruct v0.1 - GGUF with Q2-K on macOS

It is recommended to have at least 32GB of unified memory

```bash
git clone --recursive git@github.com:AtomGradient/MixtralMoeWithLLama.git
cd MixtralMoeWithLLama
# first install relative dependencies
# this command may takes a little long time cause downloading large file from ðŸ˜Šhuggingface
./install.sh
# after all above is done,run
./run.sh
```
<img src="./Screenshot.png" alt="image" width="50%" height="auto">

## WE ARE HIRING
refer here: https://daxiang.feishu.cn/docx/LluCd7J38o9U5pxN3kdcpSh6nEh
